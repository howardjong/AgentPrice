Okay, let's tackle the persistent timeout and setup instability issues. Since the previous strategies haven't fully resolved this, we need to focus on hardening the test harness itself and ensuring maximum control and predictability.

Based on your feedback that the core issues seem related to **test timeout and setup**, here are further suggestions, incorporating the idea of potentially using helper tools:

**1. Robust Test Environment Encapsulation:**

* **Problem:** Inconsistent setup/teardown logic across tests, potential for resource leaks (ports, listeners, server instances), race conditions during setup/cleanup.
* **Solution:** Create a dedicated helper class or set of functions to manage the entire lifecycle of the test environment (server, client(s), ports). This ensures consistency and proper cleanup.
    * **Key Features:**
        * **Dynamic Port Allocation:** Use a library like `get-port` (`npm install --save-dev get-port`) to find an available port for each test run or suite, preventing EADDRINUSE errors.
        * **Centralized Server Management:** Handle `httpServer` creation, `socket.io` Server instantiation, listening, and *graceful* shutdown (including waiting for the `close` event) within the helper.
        * **Controlled Client Creation:** Provide a method to create clients with enforced defaults beneficial for testing (`forceNew: true`, `autoConnect: false`) and track all created clients.
        * **Reliable Initial Connection:** Ensure the setup method includes connecting the initial client(s) and explicitly waiting for the `connect` event using your `waitForEvent` utility before the test logic begins.
        * **Bulletproof Teardown:** The teardown method *must* disconnect all tracked clients, remove their listeners, force-disconnect server-side sockets (`io.disconnectSockets(true)`), close the Socket.IO server (`io.close()`), and close the HTTP server (`httpServer.close()`), waiting where appropriate.

    ```javascript
    // Conceptual Example (Refined from previous thought process)
    import { Server } from 'socket.io';
    import { io as ioc } from 'socket.io-client';
    import { createServer } from 'http';
    import { waitForEvent } from './waitForEvent'; // Your utility
    import getPort from 'get-port';

    class SocketTestEnvironment {
      httpServer = null;
      io = null;
      clients = [];
      port = null;

      async setup() {
        this.port = await getPort();
        this.httpServer = createServer();
        this.io = new Server(this.httpServer);

        // Optional: Basic server listeners for debugging
        this.io.on('connection', socket => {
          console.log(`[Test Server] Client connected: ${socket.id}`);
          socket.on('disconnect', (reason) => {
            console.log(`[Test Server] Client disconnected: ${socket.id}, Reason: ${reason}`);
          });
        });

        await new Promise(resolve => this.httpServer.listen(this.port, resolve));
        console.log(`[Test Server] Listening on port ${this.port}`);
      }

      async createClient(options = {}) {
        const defaultOptions = {
          forceNew: true,
          autoConnect: false,
          reconnection: false, // Default: no auto reconnect unless specified
          timeout: 3000,       // Connection timeout
          // Add other test-friendly defaults
          ...options,
        };
        const client = ioc(`http://localhost:${this.port}`, defaultOptions);
        this.clients.push(client); // Track for cleanup

        // Add basic client logging automatically
        this.addDebugHandlers(client);

        return client;
      }

      // Connect a client and wait, useful after createClient
      async connectClient(client) {
         if (!client.active) { // Avoid connect if already connected
            client.connect();
         }
         try {
            await waitForEvent(client, 'connect', client.io.opts.timeout || 3000);
         } catch (err) {
            console.error(`[Test Client] Failed to connect: ${err.message}`);
            throw err; // Re-throw to fail the test clearly
         }
      }

      async stopServer() {
        if (this.io) {
          console.log('[Test Server] Forcing disconnect of server-side sockets...');
          this.io.disconnectSockets(true); // Force close connections
          // Give a brief moment for disconnects to process
          await new Promise(res => setTimeout(res, 50));
          console.log('[Test Server] Closing Socket.IO server...');
          this.io.close(); // Stop accepting new connections
          this.io = null;
        }
        if (this.httpServer && this.httpServer.listening) {
           console.log('[Test Server] Closing HTTP server...');
           await new Promise((resolve, reject) => {
             this.httpServer.close(err => {
               if (err) {
                 console.error('[Test Server] Error closing HTTP server:', err);
                 reject(err);
               } else {
                 console.log('[Test Server] HTTP server closed.');
                 resolve();
               }
             });
           });
           this.httpServer = null;
        }
      }

      async teardown() {
         console.log('[Test Env] Starting teardown...');
         for (const client of this.clients) {
            try {
              if (client.connected) {
                 console.log(`[Test Client] Disconnecting client ${client.id}...`);
                 client.disconnect();
              }
              client.removeAllListeners();
            } catch(e) { console.warn(`[Test Env] Error cleaning up client ${client.id}:`, e); }
         }
         this.clients = [];
         await this.stopServer();
         console.log('[Test Env] Teardown complete.');
      }

      addDebugHandlers(client) {
         client.on('connect', () => console.log(`[Test Client ${client.id}] Connected`));
         client.on('disconnect', (reason) => console.log(`[Test Client ${client.id}] Disconnected: ${reason}`));
         client.on('connect_error', (err) => console.error(`[Test Client ${client.id}] Connect Error: ${err.message}`));
         client.on('reconnect_attempt', (attempt) => console.log(`[Test Client ${client.id}] Reconnect Attempt #${attempt}`));
         client.on('reconnecting', (attempt) => console.log(`[Test Client ${client.id}] Reconnecting... (Attempt ${attempt})`));
         client.on('reconnect_error', (err) => console.error(`[Test Client ${client.id}] Reconnect Error: ${err.message}`));
         client.on('reconnect_failed', () => console.error(`[Test Client ${client.id}] Reconnect Failed`));
         client.on('reconnect', (attempt) => console.log(`[Test Client ${client.id}] Reconnected on attempt ${attempt}`));
      }
    }

    // Usage in test (e.g., Vitest/Jest):
    describe('Stable Socket.IO Tests', () => {
       let env;

       beforeEach(async () => {
          env = new SocketTestEnvironment();
          await env.setup();
       });

       afterEach(async () => {
          await env.teardown();
       });

       it('should connect and disconnect cleanly', async () => {
          const client = await env.createClient();
          await env.connectClient(client);
          expect(client.connected).toBe(true);
          client.disconnect();
          await waitForEvent(client, 'disconnect', 1000);
          expect(client.connected).toBe(false);
       }, 5000); // Test specific timeout if needed

       it('should handle basic reconnection simulation', async () => {
          const client = await env.createClient({ reconnection: true, reconnectionAttempts: 2, reconnectionDelay: 50, reconnectionDelayMax: 100 });
          await env.connectClient(client);
          expect(client.connected).toBe(true);

          // Simulate server going down and coming back up
          await env.stopServer();
          // Optionally wait slightly after server stop confirmed
          await new Promise(res => setTimeout(res, 100));
          await env.setup(); // Re-setup server on same port (env needs modification to reuse port)

          // Wait for the client's reconnect event
          await waitForEvent(client, 'connect', 2000); // Or 'reconnect'
          expect(client.connected).toBe(true);

       }, 10000); // Longer timeout for tests involving restarts
    });
    ```

**2. Aggressive Reconnection Settings for Tests:**

* **Problem:** Default reconnection delays are designed for production and are too long for tests, causing timeouts.
* **Solution:** When testing *actual* reconnection scenarios (not simulation), configure the client with very short delays and few attempts. This makes the reconnection succeed or fail *quickly*.
    ```javascript
    const testReconnectOptions = {
      reconnection: true,
      reconnectionAttempts: 3,     // Fail fast if it doesn't work
      reconnectionDelay: 50,       // ms - very short
      reconnectionDelayMax: 200,   // ms - also short
      randomizationFactor: 0.1,    // Reduce randomness for predictability
      timeout: 1000                // Short connection timeout
    };
    // Use when creating client for reconnect tests:
    // const client = await env.createClient(testReconnectOptions);
    ```

**3. Test Execution Control:**

* **Problem:** Tests interfering with each other due to shared resources or asynchronous operations bleeding over.
* **Solution:**
    * **Serial Execution:** Explicitly configure your test runner (Jest: `--runInBand`, Vitest: `test.sequential` or config) to run tests involving this setup sequentially, not in parallel.
    * **Increased Test Timeouts (Targeted):** Instead of a global increase, apply longer timeouts specifically to the `describe` blocks or individual `it` tests that involve server restarts and reconnection waits. This acknowledges that these operations inherently take longer. Use your test framework's syntax (e.g., `it(..., ..., timeoutMs)`).

**4. Debugging Tools and Techniques:**

* **Problem:** Hard to see *why* a timeout occurred.
* **Solution:**
    * **Verbose Logging:** Add extensive `console.log` statements within your test environment helper, client event handlers (as shown in the example `addDebugHandlers`), and server event handlers. Timestamping logs can help sequence events.
    * **Socket.IO Debug Logs:** Enable Socket.IO's own debugging logs using environment variables. This is extremely verbose but shows internal state changes.
        * For client: `DEBUG=socket.io-client:* npm test`
        * For server: `DEBUG=socket.io:* npm test`
        * Combined: `DEBUG=socket.io*,socket.io-client:* npm test` (or use your test runner command)
    * **Node.js Inspector:** Run your tests with the Node inspector enabled (`node --inspect-brk node_modules/.bin/jest ...`) and use Chrome DevTools or VS Code debugger to step through the setup, test logic, and teardown, inspecting variable states and async operations.

**5. Open Source Tools (Revisiting):**

* **`@socket.io/admin-ui`:** As mentioned before, useful for *manual debugging*. You could potentially integrate starting/stopping it within your `TestEnvironment` helper for visual inspection during failing test runs (though this adds overhead).
* **`testing-library/dom` (If applicable):** If your client-side code interacts with a UI framework (React, Vue, etc.), use the appropriate Testing Library package to interact with the UI and wait for UI changes resulting from Socket.IO events, rather than waiting directly for Socket.IO events themselves. This tests the user-facing outcome.
* **Mock Socket.IO (if not already fully embraced):** Libraries exist specifically for mocking `socket.io-client` and `socket.io` server (though often less maintained than the core library). If simulation is the chosen path, a dedicated mocking library *might* offer finer control than manual event emission, but evaluate its maintenance status and complexity. Often, careful manual simulation with standard event emitters is sufficient.

**Priority Actions:**

1.  **Implement `SocketTestEnvironment`:** This tackles setup/teardown stability head-on. Use `get-port`.
2.  **Enforce Serial Execution:** Stop parallel runs for these integration tests.
3.  **Use Aggressive Reconnect Timings:** Speed up the tests that *must* check actual reconnection.
4.  **Leverage Debug Logs:** Use `DEBUG=socket.io*` when tests fail to get maximum insight.

Start with these foundational improvements. They directly address the stated problems of setup instability and timeouts by providing more control, isolation, and faster feedback loops during tests.